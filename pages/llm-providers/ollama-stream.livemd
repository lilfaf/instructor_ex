# Local Instructor w/ Ollama (stream)

```elixir
Mix.install(
  [
    {:instructor, path: "/Users/louislarpin/Workspace/instructor_ex"},
    {:kino_shell, "~> 0.1.2"}
  ],
  config: [
    instructor: [
      adapter: Instructor.Adapters.OpenAI
    ],
    openai: [
      api_key: "ollama",
      api_url: "http://localhost:11434",
      http_options: [recv_timeout: 60_000, async: :once]
    ]
  ]
)
```

## Section

```elixir
defmodule President do
  use Ecto.Schema

  @primary_key false
  embedded_schema do
    field(:first_name, :string)
    field(:last_name, :string)
    field(:entered_office_date, :date)
  end
end

Instructor.chat_completion(
  mode: :json,
  model: "mistral:7b-instruct-q6_K",
  response_model: {:partial, President},
  stream: true,
  messages: [
    %{role: "user", content: "Who was the first president of the United States?"}
  ]
)
|> Stream.each(fn
  {:partial, president} -> IO.puts("[Partial]: #{inspect(president)}")
  {:ok, president} -> IO.puts("[Final]: #{inspect(president)}")
end)
|> Stream.run()
```
